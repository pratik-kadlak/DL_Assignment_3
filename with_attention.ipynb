{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b854aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import wandb\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a076a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "train_file = '/Users/pratikkadlak/Pratik/IITM/SEM_2/Deep_Learning/Assignment_3/aksharantar_sampled/mar/mar_train.csv'\n",
    "test_file = '/Users/pratikkadlak/Pratik/IITM/SEM_2/Deep_Learning/Assignment_3/aksharantar_sampled/mar/mar_test.csv'\n",
    "val_file = '/Users/pratikkadlak/Pratik/IITM/SEM_2/Deep_Learning/Assignment_3/aksharantar_sampled/mar/mar_valid.csv'\n",
    "\n",
    "# Read data\n",
    "train_data = pd.read_csv(train_file, header=None)\n",
    "test_data = pd.read_csv(test_file, header=None)\n",
    "val_data = pd.read_csv(val_file, header=None)\n",
    "\n",
    "# Split into English and Marathi words\n",
    "english_train = train_data.iloc[:, 0]\n",
    "marathi_train = train_data.iloc[:, 1]\n",
    "\n",
    "english_test = test_data.iloc[:, 0]\n",
    "marathi_test = test_data.iloc[:, 1]\n",
    "\n",
    "english_val = val_data.iloc[:, 0]\n",
    "marathi_val = val_data.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee83def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_char_list(words):\n",
    "    char_list = []\n",
    "    max_length_word = -1\n",
    "    for word in words:\n",
    "        max_length_word = max(max_length_word, len(word))\n",
    "        for char in word:\n",
    "            char_list.append(char)\n",
    "    char_list = list(set(char_list))\n",
    "    char_list.sort()\n",
    "    return char_list, max_length_word\n",
    "\n",
    "def find_max_length(word_list):\n",
    "    max_length = -1\n",
    "    for word in word_list:\n",
    "        max_length = max(max_length, len(word))\n",
    "    return max_length\n",
    "\n",
    "# Create character lists and find maximum word lengths\n",
    "english_chars, english_max_len = create_char_list(english_train)\n",
    "marathi_chars, marathi_max_len = create_char_list(marathi_train)\n",
    "\n",
    "# Find maximum word lengths from validation and test data\n",
    "english_max_len = max(find_max_length(english_val), find_max_length(english_test), english_max_len)\n",
    "marathi_max_len = max(find_max_length(marathi_val), find_max_length(marathi_test), marathi_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e13be74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_vector(word, lang):\n",
    "    vector = []\n",
    "    if(lang == \"english\"):\n",
    "        vector.append(len(english_chars) + 1)\n",
    "        for char in word:\n",
    "            for i in range(len(english_chars)):\n",
    "                if(english_chars[i] == char):\n",
    "                    vector.append(i+1)\n",
    "    else :\n",
    "        vector.append(len(marathi_chars) + 1)\n",
    "        for char in word:\n",
    "            for i in range(len(marathi_chars)):\n",
    "                if( marathi_chars[i] == char):\n",
    "                    vector.append(i+1)\n",
    "            \n",
    "    max_len = -1\n",
    "    if lang == \"english\": max_len = english_max_len\n",
    "    else: max_len = marathi_max_len\n",
    "        \n",
    "    while(len(vector) < max_len + 1):  # padding with max_length + 1.\n",
    "        vector.append(0)\n",
    "            \n",
    "    vector.append(0)\n",
    "    return(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2047cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating matrix of representation for whole words of english and marathi.\n",
    "def word_matrix(words, language):\n",
    "    matrix = []\n",
    "    for word in words:\n",
    "        matrix.append(word_to_vector(word, language))\n",
    "    return(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84389da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate representations of Training English and Marathi words\n",
    "english_word_representations = word_matrix(english_train, \"english\")\n",
    "marathi_word_representations = word_matrix(marathi_train, \"marathi\")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "english_matrix = torch.tensor(english_word_representations)\n",
    "marathi_matrix = torch.tensor(marathi_word_representations)\n",
    "\n",
    "# Calculate representations for validation data\n",
    "english_word_representations_val = word_matrix(english_val, \"english\")\n",
    "marathi_word_representations_val = word_matrix(marathi_val, \"marathi\")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "english_matrix_val = torch.tensor(english_word_representations_val)\n",
    "marathi_matrix_val = torch.tensor(marathi_word_representations_val)\n",
    "\n",
    "# Calculate representations for test data\n",
    "english_word_representations_test = word_matrix(english_test, \"english\")\n",
    "marathi_word_representations_test = word_matrix(marathi_test, \"marathi\")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "english_matrix_test = torch.tensor(english_word_representations_test)\n",
    "marathi_matrix_test = torch.tensor(marathi_word_representations_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a51797b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_dim, hidden_size, num_layers, batch_size, dropout_prob, bidirectional, cell_type):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.biderectional = bidirectional\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
    "        self.cell_type = cell_type\n",
    "        \n",
    "        rnn_class = nn.RNN if cell_type == \"RNN\" else (nn.LSTM if cell_type == \"LSTM\" else nn.GRU)\n",
    "        self.rnn = rnn_class(embedding_dim, hidden_size, num_layers, dropout=dropout_prob, bidirectional=bidirectional)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        if self.cell_type == \"LSTM\":\n",
    "            output, (hidden, cell) = self.rnn(embedded)\n",
    "        else:\n",
    "            output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        return (output, hidden, cell) if self.cell_type == \"LSTM\" else (output, hidden)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b82b6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
